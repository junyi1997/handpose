{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "#from utils import cpm_utils\n",
    "from config import FLAGS\n",
    "import Ensemble_data_generator\n",
    "from models.nets import cpm_hand\n",
    "import Detector as dt\n",
    "#rewrite cpm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_stats(step, lr, stage_losses, total_loss, lapse_time):\n",
    "    lapse_time = time.time() - lapse_time\n",
    "    status = 'Step: {}/{} ----- Cur_lr: {:1.7f} ----- Time: {:>2.2f} sec.'.format(step, FLAGS.training_iters,\n",
    "                                                                                 lr, lapse_time)\n",
    "    losses = ' | '.join(\n",
    "        ['S{} loss: {:>7.2f}'.format(stage_num + 1, stage_losses[stage_num]) for stage_num in range(FLAGS.total_stages)])\n",
    "    losses += ' | Total loss: {}'.format(total_loss)\n",
    "    print(status)\n",
    "    print(losses + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU setting and environment\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "model_path_suffix = os.path.join(#FLAGS.network_def,\n",
    "                                 #'input_{}_output_{}'.format(FLAGS.image_size, FLAGS.hmap_size),\n",
    "                                 #'joints_{}'.format(FLAGS.total_joints),\n",
    "                                 'stages_{}'.format(FLAGS.total_stages),\n",
    "                                 'init_{}_rate_{}_step_{}'.format(FLAGS.lr, FLAGS.l_decay_rate,\n",
    "                                                                  FLAGS.l_decay_step)\n",
    "                                 )\n",
    "model_dir = os.path.join('models',\n",
    "                              'weights',\n",
    "                              model_path_suffix)\n",
    "# train_log_dir = os.path.join('models',\n",
    "#                                   'logs',\n",
    "#                                   model_path_suffix,\n",
    "#                                   'train')\n",
    "# test_log_dir = os.path.join('models',\n",
    "#                                  'logs',\n",
    "#                                  model_path_suffix,\n",
    "#                                  'test')\n",
    "os.system('mkdir -p {}'.format(model_dir))\n",
    "# os.system('mkdir -p {}'.format(train_log_dir))\n",
    "# os.system('mkdir -p {}'.format(test_log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator for data\n",
    "train_itr = Ensemble_data_generator.ensemble_data_generator(FLAGS.train_tf_file, FLAGS.batch_size, FLAGS.image_size, FLAGS.box_size)\n",
    "val_itr = Ensemble_data_generator.ensemble_data_generator(FLAGS.val_tf_file, FLAGS.batch_size, FLAGS.image_size, FLAGS.box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Summary name total loss train is illegal; using total_loss_train instead.\n",
      "INFO:tensorflow:Summary name total loss eval is illegal; using total_loss_eval instead.\n",
      "WARNING:tensorflow:From /home/qiaohe/convolutional-pose-machines-tensorflow/models/nets/cpm_hand.py:294: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "INFO:tensorflow:Summary name global learning rate is illegal; using global_learning_rate instead.\n",
      "============Model Build============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = cpm_hand.CPM_Model(input_size=FLAGS.image_size,\n",
    "                            heatmap_size=FLAGS.hmap_size,\n",
    "                            stages=FLAGS.total_stages,\n",
    "                            joints=FLAGS.total_joints,\n",
    "                            img_type=FLAGS.color_channel,\n",
    "                            #is_training=True\n",
    "                          )\n",
    "model.build_loss(FLAGS.lr, FLAGS.l_decay_rate, FLAGS.l_decay_step, FLAGS.optimizer)\n",
    "print('============Model Build============\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged summary\n",
    "#summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here comes training\n",
    "device_count = {'GPU': 1} if FLAGS.use_gpu else {'GPU': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session(config=tf.ConfigProto(device_count=device_count,\n",
    "                                      #allow_soft_placement=True)) as sess:\n",
    "sess = tf.Session(config=tf.ConfigProto(device_count=device_count,\n",
    "                                      allow_soft_placement=True))\n",
    "#print(sess.run(tf.constant(5.0)))\n",
    "\n",
    "#sess.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare writer\n",
    "# train_log = tf.summary.FileWriter(train_log_dir, sess.graph)\n",
    "# test_log = tf.summary.FileWriter(test_log_dir, sess.graph)\n",
    "\n",
    "# Prepare saver for check points\n",
    "saver = tf.train.Saver(max_to_keep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial and run all varaibles\n",
    "ini_var = tf.global_variables_initializer()\n",
    "sess.run(ini_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/weights/stages_3/init_0.001_rate_0.5_step_10000/cpm_hand-25\n",
      "sub_stages/sub_conv1/kernel:0 7.1884307e-07\n",
      "sub_stages/sub_conv1/bias:0 -0.062977694\n",
      "sub_stages/sub_conv2/kernel:0 -0.014183093\n",
      "sub_stages/sub_conv2/bias:0 -0.02089065\n",
      "sub_stages/sub_conv3/kernel:0 -0.010057366\n",
      "sub_stages/sub_conv3/bias:0 -0.023240633\n",
      "sub_stages/sub_conv4/kernel:0 -0.0075200466\n",
      "sub_stages/sub_conv4/bias:0 -0.012945773\n",
      "sub_stages/sub_conv5/kernel:0 -0.006789395\n",
      "sub_stages/sub_conv5/bias:0 -0.021166358\n",
      "sub_stages/sub_conv6/kernel:0 -0.0061496906\n",
      "sub_stages/sub_conv6/bias:0 -0.014797414\n",
      "sub_stages/sub_conv7/kernel:0 -0.0056853276\n",
      "sub_stages/sub_conv7/bias:0 -0.028810794\n",
      "sub_stages/sub_conv8/kernel:0 -0.0068090986\n",
      "sub_stages/sub_conv8/bias:0 -0.027335651\n",
      "sub_stages/sub_conv9/kernel:0 -0.005523199\n",
      "sub_stages/sub_conv9/bias:0 -0.021066973\n",
      "sub_stages/sub_conv10/kernel:0 -0.0056791846\n",
      "sub_stages/sub_conv10/bias:0 -0.0031514685\n",
      "sub_stages/sub_conv11/kernel:0 -0.004230501\n",
      "sub_stages/sub_conv11/bias:0 -0.012977488\n",
      "sub_stages/sub_conv12/kernel:0 -0.0048765987\n",
      "sub_stages/sub_conv12/bias:0 -0.014583866\n",
      "sub_stages/sub_conv13/kernel:0 -0.004345584\n",
      "sub_stages/sub_conv13/bias:0 -0.016428132\n",
      "sub_stages/sub_conv14/kernel:0 -0.0043076924\n",
      "sub_stages/sub_conv14/bias:0 0.00053697184\n",
      "sub_stages/sub_stage_img_feature/kernel:0 -0.009305793\n",
      "sub_stages/sub_stage_img_feature/bias:0 0.022123989\n",
      "stage_1/conv1/kernel:0 -0.042466477\n",
      "stage_1/conv1/bias:0 0.008108424\n",
      "stage_1/stage_heatmap/kernel:0 -0.0004380949\n",
      "stage_1/stage_heatmap/bias:0 0.022777574\n",
      "stage_2/mid_conv1/kernel:0 -0.0035184438\n",
      "stage_2/mid_conv1/bias:0 -0.008076478\n",
      "stage_2/mid_conv2/kernel:0 -0.0025887135\n",
      "stage_2/mid_conv2/bias:0 -0.037375335\n",
      "stage_2/mid_conv3/kernel:0 -0.009023119\n",
      "stage_2/mid_conv3/bias:0 0.003136993\n",
      "stage_2/mid_conv4/kernel:0 -0.0064483527\n",
      "stage_2/mid_conv4/bias:0 -0.03775207\n",
      "stage_2/mid_conv5/kernel:0 -0.025933491\n",
      "stage_2/mid_conv5/bias:0 0.055043165\n",
      "stage_2/mid_conv6/kernel:0 -0.019468877\n",
      "stage_2/mid_conv6/bias:0 0.06099799\n",
      "stage_2/mid_conv7/kernel:0 0.00017365419\n",
      "stage_2/mid_conv7/bias:0 0.031442907\n",
      "stage_3/mid_conv1/kernel:0 -0.004501176\n",
      "stage_3/mid_conv1/bias:0 -0.012299234\n",
      "stage_3/mid_conv2/kernel:0 -0.0044750506\n",
      "stage_3/mid_conv2/bias:0 -0.04251428\n",
      "stage_3/mid_conv3/kernel:0 -0.007845045\n",
      "stage_3/mid_conv3/bias:0 -0.016153436\n",
      "stage_3/mid_conv4/kernel:0 -0.003990441\n",
      "stage_3/mid_conv4/bias:0 -0.045482825\n",
      "stage_3/mid_conv5/kernel:0 -0.03043538\n",
      "stage_3/mid_conv5/bias:0 0.12472469\n",
      "stage_3/mid_conv6/kernel:0 -0.026219122\n",
      "stage_3/mid_conv6/bias:0 0.072204724\n",
      "stage_3/mid_conv7/kernel:0 -0.00031492134\n",
      "stage_3/mid_conv7/bias:0 0.03225931\n"
     ]
    }
   ],
   "source": [
    "# Load model, if already have one\n",
    "if FLAGS.pretrained_model != '':\n",
    "    saver.restore(sess, os.path.join(model_dir, FLAGS.pretrained_model))\n",
    "    \n",
    "    # show the hyperparamters\n",
    "    for var in tf.trainable_variables():\n",
    "        with tf.variable_scope('', reuse=True):\n",
    "            v = tf.get_variable(var.name[:-2])\n",
    "            print(var.name, np.mean(sess.run(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.training_iters = 10\n",
    "FLAGS.validation_iters = 10 #1000 \n",
    "FLAGS.model_save_iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 25097/10 ----- Cur_lr: 0.0001756 ----- Time: 1.39 sec.\n",
      "S1 loss:    3.49 | S2 loss:    3.10 | S3 loss:    2.52 | Total loss: 9.11156940460205\n",
      "\n",
      "Step: 25098/10 ----- Cur_lr: 0.0001756 ----- Time: 0.56 sec.\n",
      "S1 loss:   12.41 | S2 loss:    9.31 | S3 loss:    8.73 | Total loss: 30.443279266357422\n",
      "\n",
      "Step: 25099/10 ----- Cur_lr: 0.0001756 ----- Time: 0.55 sec.\n",
      "S1 loss:    9.65 | S2 loss:    7.03 | S3 loss:    6.17 | Total loss: 22.85114860534668\n",
      "\n",
      "\n",
      "Validation loss: 22961.14\n",
      "\n",
      "INFO:tensorflow:models/weights/stages_3/init_0.001_rate_0.5_step_10000/cpm_hand-25100 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "\n",
      "Model checkpoint has been saved for 25100 steps\n",
      "\n",
      "Step: 25100/10 ----- Cur_lr: 0.0001756 ----- Time: 0.54 sec.\n",
      "S1 loss:   12.52 | S2 loss:    9.56 | S3 loss:    8.53 | Total loss: 30.61001205444336\n",
      "\n",
      "Step: 25101/10 ----- Cur_lr: 0.0001755 ----- Time: 0.56 sec.\n",
      "S1 loss:   21.73 | S2 loss:   18.29 | S3 loss:   18.09 | Total loss: 58.10803985595703\n",
      "\n",
      "Step: 25102/10 ----- Cur_lr: 0.0001755 ----- Time: 0.55 sec.\n",
      "S1 loss:    9.83 | S2 loss:    7.90 | S3 loss:    7.26 | Total loss: 24.983928680419922\n",
      "\n",
      "Step: 25103/10 ----- Cur_lr: 0.0001755 ----- Time: 0.55 sec.\n",
      "S1 loss:    7.92 | S2 loss:    6.81 | S3 loss:    6.70 | Total loss: 21.43092918395996\n",
      "\n",
      "Step: 25104/10 ----- Cur_lr: 0.0001755 ----- Time: 0.56 sec.\n",
      "S1 loss:   14.65 | S2 loss:    9.22 | S3 loss:    8.13 | Total loss: 31.999465942382812\n",
      "\n",
      "Step: 25105/10 ----- Cur_lr: 0.0001755 ----- Time: 0.55 sec.\n",
      "S1 loss:   19.37 | S2 loss:   15.41 | S3 loss:   15.21 | Total loss: 49.98567199707031\n",
      "\n",
      "Step: 25106/10 ----- Cur_lr: 0.0001755 ----- Time: 0.55 sec.\n",
      "S1 loss:   17.09 | S2 loss:   12.50 | S3 loss:   11.73 | Total loss: 41.32157516479492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training iteration starts:\n",
    "# tmp_storing_list1 = []\n",
    "# tmp_storing_list2 = []\n",
    "next_ele = train_itr.next()\n",
    "for _ in range(FLAGS.training_iters):\n",
    "    # time records \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # get data and label from generator\n",
    "    \n",
    "    \n",
    "    batch_img, batch_joints = sess.run(next_ele)\n",
    "#     tmp_storing_list1.append(batch_img)\n",
    "#     tmp_storing_list2.append(batch_joints)\n",
    "    \n",
    "    # normalize \n",
    "    batch_img = batch_img / 255 - 0.5\n",
    "        \n",
    "    # express label in the form of a heatmap\n",
    "    batch_heatmap = dt.transform_joints_to_heatmap(FLAGS.image_size, FLAGS.hmap_size,\n",
    "                                                        FLAGS.joint_gaussian_variance,\n",
    "                                                        batch_joints)\n",
    "    \n",
    "    \n",
    "    # go forward one step and prepare record\n",
    "    stage_loss, total_loss, op, cur_lr, stage_heatmap, global_step = sess.run([model.stage_loss, # loss of each stage\n",
    "              model.total_loss, # sum loss of all stages\n",
    "              model.train_op, # optimization, this must be done, otherwise the global step will not increment\n",
    "              #summary,# summary\n",
    "              model.cur_lr, # depreciating\n",
    "              model.stage_heatmap, # heatmaps of each stage\n",
    "              model.global_step # count steps\n",
    "              ],feed_dict={model.input_images: batch_img,model.gt_hmap_placeholder: batch_heatmap})\n",
    "    \n",
    "    # display record\n",
    "    display_training_stats(global_step, cur_lr, stage_loss, total_loss, t0)\n",
    "    \n",
    "    # store train summary\n",
    "    #train_log.add_summary(summaries, global_step)\n",
    "    \n",
    "    # intermediate results for debugging\n",
    "    # Draw intermediate results\n",
    "    if (global_step + 1) % 10 == 0:\n",
    "        if FLAGS.color_channel == 'GRAY':\n",
    "            demo_img = np.repeat(batch_img[0], 3, axis=2)\n",
    "            demo_img += 0.5\n",
    "        elif FLAGS.color_channel == 'RGB':\n",
    "            demo_img = batch_img[0] + 0.5\n",
    "        else:\n",
    "            raise ValueError('Non support image type.')\n",
    "\n",
    "#         demo_stage_heatmaps = []\n",
    "#         for stage in range(FLAGS.total_stages):\n",
    "#             demo_stage_heatmap = stage_heatmap[stage][0, :, :, 0:FLAGS.total_joints].reshape(\n",
    "#                 (FLAGS.hmap_size, FLAGS.hmap_size, FLAGS.total_joints))\n",
    "#             demo_stage_heatmap = cv2.resize(demo_stage_heatmap, (FLAGS.image_size, FLAGS.image_size))\n",
    "#             demo_stage_heatmap = np.amax(demo_stage_heatmap, axis=2)\n",
    "#             demo_stage_heatmap = np.reshape(demo_stage_heatmap, (FLAGS.image_size, FLAGS.image_size, 1))\n",
    "#             demo_stage_heatmap = np.repeat(demo_stage_heatmap, 3, axis=2)\n",
    "#             demo_stage_heatmaps.append(demo_stage_heatmap)\n",
    "\n",
    "#         demo_gt_heatmap = batch_heatmap[0, :, :, 0:FLAGS.total_joints].reshape(\n",
    "#             (FLAGS.hmap_size, FLAGS.hmap_size, FLAGS.total_joints))\n",
    "#         demo_gt_heatmap = cv2.resize(demo_gt_heatmap, (FLAGS.image_size, FLAGS.image_size))\n",
    "#         demo_gt_heatmap = np.amax(demo_gt_heatmap, axis=2)\n",
    "#         demo_gt_heatmap = np.reshape(demo_gt_heatmap, (FLAGS.image_size, FLAGS.image_size, 1))\n",
    "#         demo_gt_heatmap = np.repeat(demo_gt_heatmap, 3, axis=2)\n",
    "\n",
    "#         if FLAGS.total_stages > 4:\n",
    "#             upper_img = np.concatenate((demo_stage_heatmaps[0], demo_stage_heatmaps[1], demo_stage_heatmaps[2]),\n",
    "#                                        axis=1)\n",
    "#             if FLAGS.normalize_img:\n",
    "#                 blend_img = 0.5 * demo_img + 0.5 * demo_gt_heatmap\n",
    "#             else:\n",
    "#                 blend_img = 0.5 * demo_img / 255.0 + 0.5 * demo_gt_heatmap\n",
    "#             lower_img = np.concatenate((demo_stage_heatmaps[FLAGS.total_stages - 1], demo_gt_heatmap, blend_img),\n",
    "#                                        axis=1)\n",
    "#             demo_img = np.concatenate((upper_img, lower_img), axis=0)\n",
    "#             #cv2.imshow('current heatmap', (demo_img * 255).astype(np.uint8))\n",
    "#             #cv2.waitKey(1000)\n",
    "#             cv2.imwrite(\"/home/qiaohe/convolutional-pose-machines-tensorflow/validation_img/\" + str(global_step) + \".jpg\", demo_img * 255)\n",
    "\n",
    "#         else:\n",
    "#             upper_img = np.concatenate((demo_stage_heatmaps[FLAGS.total_stages - 1], demo_gt_heatmap, demo_img),\n",
    "#                                        axis=1)\n",
    "#             #cv2.imshow('current heatmap', (upper_img * 255).astype(np.uint8))\n",
    "#             #cv2.waitKey(1000) \n",
    "#             cv2.imwrite(\"/home/qiaohe/convolutional-pose-machines-tensorflow/validation_img/\" + str(global_step) + \".jpg\", upper_img * 255)\n",
    "\n",
    "    # validates every some iterations\n",
    "    if (global_step + 1) % FLAGS.validation_iters == 0:\n",
    "        mean_loss = 0\n",
    "        for i in range(FLAGS.validation_batch_per_iter):\n",
    "            batch_img_test, batch_joints_test = val_itr.next()\n",
    "            batch_img_test, batch_joints_test = sess.run([batch_img_test, batch_joints_test])\n",
    "            \n",
    "            # express label in the form of a heatmap\n",
    "            batch_heatmap_test = dt.transform_joints_to_heatmap(FLAGS.image_size,\n",
    "                                                                     FLAGS.hmap_size,\n",
    "                                                                     FLAGS.joint_gaussian_variance,\n",
    "                                                                     batch_joints_test)\n",
    "            \n",
    "            \n",
    "            # go forward one step and prepare record\n",
    "            total_loss_test = sess.run(model.total_loss # sum loss of all stages\n",
    "                                              #summary,# summary\n",
    "                                             , feed_dict={model.input_images: batch_img_test,\n",
    "                                                                   model.gt_hmap_placeholder: batch_heatmap_test})\n",
    "\n",
    "            mean_loss += total_loss_test\n",
    "        print('\\nValidation loss: {:>7.2f}\\n'.format(mean_loss / FLAGS.validation_batch_per_iter))\n",
    "        #test_log.add_summary(summaries_test, global_step)\n",
    "    \n",
    "    # save model\n",
    "    if (global_step + 1) % FLAGS.model_save_iters == 0:\n",
    "        saver.save(sess=sess, save_path=os.path.join(model_dir, FLAGS.network_def),\n",
    "                   global_step=(global_step + 1))\n",
    "        print('\\nModel checkpoint has been saved for {:d} steps\\n'.format(global_step + 1))\n",
    "    \n",
    "    # end training\n",
    "    if global_step == FLAGS.training_iters:\n",
    "        print('\\n{:d} steps have been finished, training ends\\n'.format(global_step))\n",
    "        break\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n",
      "[[[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]\n",
      "\n",
      " [[False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]\n",
      "  [False False]]]\n"
     ]
    }
   ],
   "source": [
    "#len(np.unique(tmp_storing_list1))\n",
    "for i in range(len(tmp_storing_list2) - 1):\n",
    "    print(tmp_storing_list2[i] == tmp_storing_list2[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
